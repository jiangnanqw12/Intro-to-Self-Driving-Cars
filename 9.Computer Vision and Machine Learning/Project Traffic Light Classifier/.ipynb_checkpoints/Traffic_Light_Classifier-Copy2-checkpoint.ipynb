{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Light Classifier\n",
    "---\n",
    "\n",
    "In this project, youâ€™ll use your knowledge of computer vision techniques to build a classifier for images of traffic lights! You'll be given a dataset of traffic light images in which one of three lights is illuminated: red, yellow, or green.\n",
    "\n",
    "In this notebook, you'll pre-process these images, extract features that will help us distinguish the different types of images, and use those features to classify the traffic light images into three classes: red, yellow, or green. The tasks will be broken down into a few sections:\n",
    "\n",
    "1. **Loading and visualizing the data**. \n",
    "      The first step in any classification task is to be familiar with your data; you'll need to load in the images of traffic lights and visualize them!\n",
    "\n",
    "2. **Pre-processing**. \n",
    "    The input images and output labels need to be standardized. This way, you can analyze all the input images using the same classification pipeline, and you know what output to expect when you eventually classify a *new* image.\n",
    "    \n",
    "3. **Feature extraction**. \n",
    "    Next, you'll extract some features from each image that will help distinguish and eventually classify these images.\n",
    "   \n",
    "4. **Classification and visualizing error**. \n",
    "    Finally, you'll write one function that uses your features to classify *any* traffic light image. This function will take in an image and output a label. You'll also be given code to determine the accuracy of your classification model.    \n",
    "    \n",
    "5. **Evaluate your model**.\n",
    "    To pass this project, your classifier must be >90% accurate and never classify any red lights as green; it's likely that you'll need to improve the accuracy of your classifier by changing existing features or adding new features. I'd also encourage you to try to get as close to 100% accuracy as possible!\n",
    "    \n",
    "Here are some sample images from the dataset (from left to right: red, green, and yellow traffic lights):\n",
    "<img src=\"images/all_lights.png\" width=\"50%\" height=\"50%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### *Here's what you need to know to complete the project:*\n",
    "\n",
    "Some template code has already been provided for you, but you'll need to implement additional code steps to successfully complete this project. Any code that is required to pass this project is marked with **'(IMPLEMENTATION)'** in the header. There are also a couple of questions about your thoughts as you work through this project, which are marked with **'(QUESTION)'** in the header. Make sure to answer all questions and to check your work against the [project rubric](https://review.udacity.com/#!/rubrics/1213/view) to make sure you complete the necessary classification steps!\n",
    "\n",
    "Your project submission will be evaluated based on the code implementations you provide, and on two main classification criteria.\n",
    "Your complete traffic light classifier should have:\n",
    "1. **Greater than 90% accuracy**\n",
    "2. ***Never* classify red lights as green**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading and Visualizing the Traffic Light Dataset\n",
    "\n",
    "This traffic light dataset consists of 1484 number of color images in 3 categories - red, yellow, and green. As with most human-sourced data, the data is not evenly distributed among the types. There are:\n",
    "* 904 red traffic light images\n",
    "* 536 green traffic light images\n",
    "* 44 yellow traffic light images\n",
    "\n",
    "*Note: All images come from this [MIT self-driving car course](https://selfdrivingcars.mit.edu/) and are licensed under a [Creative Commons Attribution-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import resources\n",
    "\n",
    "Before you get started on the project code, import the libraries and resources that you'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # computer vision library\n",
    "import helpers # helper functions\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg # for loading in images\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image data directories\n",
    "IMAGE_DIR_TRAINING = \"traffic_light_images/training/\"\n",
    "IMAGE_DIR_TEST = \"traffic_light_images/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the load_dataset function in helpers.py\n",
    "# Load training data\n",
    "IMAGE_LIST = helpers.load_dataset(IMAGE_DIR_TRAINING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2199445e5f8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## TODO: Write code to display an image in IMAGE_LIST (try finding a yellow traffic light!)\n",
    "## TODO: Print out 1. The shape of the image and 2. The image's label\n",
    "\n",
    "# The first image in IMAGE_LIST is displayed below (without information about shape or label)\n",
    "selected_image = IMAGE_LIST[0][0]\n",
    "plt.imshow(selected_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should take in an RGB image and return a new, standardized version\n",
    "def standardize_input(image):\n",
    "    \n",
    "    ## TODO: Resize image and pre-process so that all \"standard\" images are the same size  \n",
    "    standard_im = np.copy(image)\n",
    "    cv2.resize(standard_im,(32,32))\n",
    "    return standard_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: One hot encode an image label\n",
    "## Given a label - \"red\", \"green\", or \"yellow\" - return a one-hot encoded label\n",
    "\n",
    "# Examples: \n",
    "# one_hot_encode(\"red\") should return: [1, 0, 0]\n",
    "# one_hot_encode(\"yellow\") should return: [0, 1, 0]\n",
    "# one_hot_encode(\"green\") should return: [0, 0, 1]\n",
    "\n",
    "def one_hot_encode(label):\n",
    "    \n",
    "    ## TODO: Create a one-hot encoded label that works for all classes of traffic lights\n",
    "    one_hot_encoded = [] \n",
    "    if label==\"red\":\n",
    "        one_hot_encoded=[1,0,0]\n",
    "    elif label==\"yellow\":\n",
    "        one_hot_encoded=[0,1,0]\n",
    "    else:\n",
    "        one_hot_encoded=[0,0,1]\n",
    "    \n",
    "    return one_hot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**<span style=\"color: green;\">TEST PASSED</span>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing the tests\n",
    "import test_functions\n",
    "tests = test_functions.Tests()\n",
    "\n",
    "# Test for one_hot_encode function\n",
    "tests.test_one_hot(one_hot_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(image_list):\n",
    "    \n",
    "    # Empty image data array\n",
    "    standard_list = []\n",
    "\n",
    "    # Iterate through all the image-label pairs\n",
    "    for item in image_list:\n",
    "        image = item[0]\n",
    "        label = item[1]\n",
    "\n",
    "        # Standardize the image\n",
    "        standardized_im = standardize_input(image)\n",
    "\n",
    "        # One-hot encode the label\n",
    "        one_hot_label = one_hot_encode(label)    \n",
    "\n",
    "        # Append the image, and it's one hot encoded label to the full, processed list of image data \n",
    "        standard_list.append((standardized_im, one_hot_label))\n",
    "        \n",
    "    return standard_list\n",
    "\n",
    "# Standardize all training images\n",
    "STANDARDIZED_LIST = standardize(IMAGE_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crop_image(image):\n",
    "    row_crop=3\n",
    "    col_crop=10\n",
    "    return image[row_crop:-row_crop,col_crop:-col_crop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature(rgb_image):\n",
    "    \n",
    "    ## TODO: Convert image to HSV color space\n",
    "    hsv=cv2.cvtColor(rgb_image,cv2.COLOR_RGB2HSV)\n",
    "    v=hsv[:,:,2]\n",
    "    \n",
    "    ## TODO: Create and return a feature value and/or vector\n",
    "    feature = []\n",
    "    feature=np.sum(get_crop_image(v),axis=1)\n",
    "    \n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-bfaea2b88bc0>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-bfaea2b88bc0>\"\u001b[1;36m, line \u001b[1;32m17\u001b[0m\n\u001b[1;33m    predicted_label=[0,0,1]dd\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# This function should take in RGB image input\n",
    "# Analyze that image using your feature creation code and output a one-hot encoded label\n",
    "def estimate_label(rgb_image):\n",
    "    \n",
    "    ## TODO: Extract feature(s) from the RGB image and use those features to\n",
    "    ## classify the image and output a one-hot encoded label\n",
    "    predicted_label = []\n",
    "    croped_image=get_crop_image(rgb_image)\n",
    "    feature=create_feature(rgb_image)\n",
    "    red=np.sum(feature[0:10])\n",
    "    yellow=np.sum(feature[12:17])\n",
    "    green=np.sum(feature[16:])\n",
    "    if red>yellow:\n",
    "        if red >green:\n",
    "            predicted_label=[1,0,0]\n",
    "        else:\n",
    "            predicted_label=[0,0,1]\n",
    "                \n",
    "    else:\n",
    "        if yellow>green:\n",
    "            predicted_label=[0,1,0]\n",
    "        else:\n",
    "            predicted_label=[0,0,1]\n",
    "              \n",
    "    return predicted_label   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the load_dataset function in helpers.py\n",
    "# Load test data\n",
    "TEST_IMAGE_LIST = helpers.load_dataset(IMAGE_DIR_TEST)\n",
    "\n",
    "# Standardize the test data\n",
    "STANDARDIZED_TEST_LIST = standardize(TEST_IMAGE_LIST)\n",
    "\n",
    "# Shuffle the standardized test data\n",
    "random.shuffle(STANDARDIZED_TEST_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructs a list of misclassified images given a list of test images and their labels\n",
    "# This will throw an AssertionError if labels are not standardized (one-hot encoded)\n",
    "\n",
    "def get_misclassified_images(test_images):\n",
    "    # Track misclassified images by placing them into a list\n",
    "    misclassified_images_labels = []\n",
    "\n",
    "    # Iterate through all the test images\n",
    "    # Classify each image and compare to the true label\n",
    "    for image in test_images:\n",
    "\n",
    "        # Get true data\n",
    "        im = image[0]\n",
    "        true_label = image[1]\n",
    "        assert(len(true_label) == 3), \"The true_label is not the expected length (3).\"\n",
    "\n",
    "        # Get predicted label from your classifier\n",
    "        predicted_label = estimate_label(im)\n",
    "        assert(len(predicted_label) == 3), \"The predicted_label is not the expected length (3).\"\n",
    "\n",
    "        # Compare true and predicted labels \n",
    "        if(predicted_label != true_label):\n",
    "            # If these labels are not equal, the image has been misclassified\n",
    "            misclassified_images_labels.append((im, predicted_label, true_label))\n",
    "            \n",
    "    # Return the list of misclassified [image, predicted_label, true_label] values\n",
    "    return misclassified_images_labels\n",
    "\n",
    "\n",
    "# Find all misclassified images in a given test set\n",
    "MISCLASSIFIED = get_misclassified_images(STANDARDIZED_TEST_LIST)\n",
    "\n",
    "# Accuracy calculations\n",
    "total = len(STANDARDIZED_TEST_LIST)\n",
    "num_correct = total - len(MISCLASSIFIED)\n",
    "accuracy = num_correct/total\n",
    "\n",
    "print('Accuracy: ' + str(accuracy))\n",
    "print(\"Number of misclassified images = \" + str(len(MISCLASSIFIED)) +' out of '+ str(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the tests\n",
    "import test_functions\n",
    "tests = test_functions.Tests()\n",
    "\n",
    "if(len(MISCLASSIFIED) > 0):\n",
    "    # Test code for one_hot_encode function\n",
    "    tests.test_red_as_green(MISCLASSIFIED)\n",
    "else:\n",
    "    print(\"MISCLASSIFIED may not have been populated with images.\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
